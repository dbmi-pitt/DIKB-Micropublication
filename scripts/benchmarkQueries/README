############################################################################
Benchmark query performance
############################################################################

--------------------------
Method
--------------------------

Case 1:

Benchmark query performance by execute all queries across 7 different size of MP (Micropublication) graphs including original MP graph and 6 folded testing graphs. Folded graph doubling size from 2 times of original MP graph to 64 times. For each query, output is query performance table that have columns, graph name, folded times, number of triples and time cost in csv file. Using number of triples and time costs, two dimensional scatter diagram will be created to concisely describe the trends of query performance with increasing size of MP graph. 
 
Specifically, Original DDI data comes from existing DIKB (Drug interaction knowledge base 1.2) with assertion that typed as "inhibits", "does not inhibits", "substrate of", "is not substrate of", "increase auc". Python based parsing program query DIKB 1.2 via D2R server by sparql query that pulls assertions, evidences supports or refutes, and drug/ingredient entity label and URI. Then, shape and fill data into well designed MP model (point to cmap model or model image) to create original MP graph. MP graph creating program receives fold times as parameter to create MP graphs from 1 to 6 folds. All items in those folded MP graphs will keep same relationships compare to original graph so that all items in folded graph should be evenly distributed.

Upload 7 MP graphs to a single virtuoso endpoint. Query testing program will take over the work that execute all queries in folder "../queries/benchmark-queries/" on 7 MP graphs and output performance table for each query.

--------------------------
Results
--------------------------

Original MP graph and folded graphs:

(1) original MP graph: 13636 triples, 1.8 MB

(2) 1 fold: 26988 triples, 3.4 MB

(3) 2 folds: 53692 triples, 6.7 MB

(4) 3 folds: 107100 triples, 14 MB

(5) 4 folds: 213916 triples, 27 MB

(6) 5 folds: 427548 triples, 54 MB

(7) 6 folds: 854812 triples, 107 MB


-------------------------------
How to run benchmark testing
-------------------------------

(1) create graph with number of folds

$ cd scripts/mp-scripts

$ dikbv1.2-to-MP-plus-OA.py <number of folds> <output graph> <output csv>

ex. $ python dikbv1.2-to-MP-plus-OA.py 3 "../../data/mp-graphs/dikb-mp-fold-3.xml" "../../data/mp-graphs/processed-dikb-ddis-fold-3.tsv"

ex. $ python dikbv1.2-to-MP-plus-OA.py 0 "../../data/mp-graphs/initial-dikb-mp-oa.xml" "../../data/mp-graphs/processed-dikb-ddis.tsv"

(2) run protege inference engine for each graph and load exported graph into Virtuso via isql-vt or via browser http://<hostname>:8890/conductor

(3) run query testing program

$ cd scripts/benchmarkQueries

$ python benchMarkQueries.py

outputs: queryBenchmark.csv


--------------------------------------
How to create benchmark diagram via R
--------------------------------------

(1) Preparations

Install: Emacs, ESS for use R in emacs, R 

write config file graph-config.properties
config for script benchMarkQueries.py to run queries on different graphs
format: <folded times>=<graph name> 


(2) get time cost of 24 queries on original MP graph

merge time cost table "queryBenchmark.csv" to format that R needs
$ mergeResultsForR.sh


(2) R command:

$ mp0 <- c()
$ mp1 <- c() ....

png('benchmark.png')

$ boxplot(mp0,mp1,mp2,mp3,mp4,mp5,mp6,vertical=TRUE, names=c("MP graph", "1 fold", "2 fold", "3 fold", "4 fold", "5 fold", "6 fold"), xlab="number of folds", ylab="time costs")

Example "createBenchMarkDiagram.R"