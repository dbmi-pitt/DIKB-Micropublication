############################################################################
Benchmark query performance
############################################################################

--------------------------
Method
--------------------------

Case 1:

Benchmark query performance by execute all queries across 7 different size of MP (Micropublication) graphs including original MP graph and 6 folded testing graphs. Folded graph doubling size from 2 times of original MP graph to 64 times. For each query, output is query performance table that have columns, graph name, folded times, number of triples and time cost in csv file. Using number of triples and time costs, two dimensional scatter diagram will be created to concisely describe the trends of query performance with increasing size of MP graph. 
 
Specifically, Original DDI data comes from existing DIKB (Drug interaction knowledge base 1.2) with assertion that typed as "inhibits", "does not inhibits", "substrate of", "is not substrate of", "increase auc". Python based parsing program query DIKB 1.2 via D2R server by sparql query that pulls assertions, evidences supports or refutes, and drug/ingredient entity label and URI. Then, shape and fill data into well designed MP model (point to cmap model or model image) to create original MP graph. MP graph creating program receives fold times as parameter to create MP graphs from 1 to 6 folds. All items in those folded MP graphs will keep same relationships compare to original graph so that all items in folded graph should be evenly distributed.

Upload 7 MP graphs to a single virtuoso endpoint. Query testing program will take over the work that execute all queries in folder "../queries/benchmark-queries/" on 7 MP graphs and output performance table for each query.

--------------------------
Results
--------------------------

Original MP graph and folded graphs (updated at 08/13/2015):

(1) original MP graph: 16670 triples, 2.0 MB

(2) 1 fold: 32674 triples, 4.0 MB

(3) 2 folds: 64682 triples, 7.8 MB

(4) 3 folds: 128698 triples, 16 MB

(5) 4 folds: 256730 triples, 31 MB

(6) 5 folds: 512794 triples, 62 MB

(7) 6 folds: 1024922 triples, 124 MB


---------------------------------------------------
Machine hardware specification (virtuoso endpoint)
---------------------------------------------------

CPU Intel(R) Core(TM)2 Duo CPU     E6550  @ 2.33GHz
8 GB RAM

-------------------------------
How to run benchmark testing
-------------------------------

(1) create graph with number of folds

$ cd scripts/mp-scripts

$ dikbv1.2-to-MP-plus-OA.py <number of folds> <output graph> <output csv>

ex. $ python dikbv1.2-to-MP-plus-OA.py 3 "../../data/mp-graphs/dikb-mp-fold-3.xml" "../../data/mp-graphs/processed-dikb-ddis-fold-3.tsv"

ex. $ python dikbv1.2-to-MP-plus-OA.py 0 "../../data/mp-graphs/initial-dikb-mp-oa.xml" "../../data/mp-graphs/processed-dikb-ddis.tsv"

(2) run protege inference engine for each graph and load exported graph into Virtuso via isql-vt or via browser http://<hostname>:8890/conductor

(3) run query testing program

$ cd scripts/benchmarkQueries

$ python benchMarkQueries.py

outputs: queryBenchmark.csv


--------------------------------------
How to create benchmark diagram via R
--------------------------------------

(1) Preparations

Install: Emacs, ESS for use R in emacs, R 

write config file graph-config.properties
config for script benchMarkQueries.py to run queries on different graphs
format: <folded times>=<graph name> 


(2) get time cost of 24 queries on original MP graph

merge time cost table "queryBenchmark.csv" to format that R needs
$ mergeResultsForR.sh


(2) R command:

$ mp0 <- c()
$ mp1 <- c() ....

png('benchmark.png')

$ boxplot(mp0,mp1,mp2,mp3,mp4,mp5,mp6,vertical=TRUE, names=c("MP graph", "1 fold", "2 fold", "3 fold", "4 fold", "5 fold", "6 fold"), xlab="number of folds", ylab="time costs")

Example "createBenchMarkDiagram.R"